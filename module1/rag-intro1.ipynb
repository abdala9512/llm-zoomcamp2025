{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ec5ad9-042a-42ab-b0aa-2e5368b9e5e5",
   "metadata": {},
   "source": [
    "# Module 1 - LLM Zoomcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787780a0-a654-4dd6-8e98-2c72640590e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad2a5b9-eea7-4cbe-a69f-6ab299896cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89d9f9a-3393-4e0d-8da0-16def9512f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659e747d-bed0-4fcb-893a-5411affd437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "     {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"List 5 tools or libraries to do High frequency trading\"\n",
    "    }   \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0208e18c-9e39-47a0-aa6d-b534f795a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-frequency trading (HFT) requires sophisticated tools and libraries to handle large volumes of data, execute trades with low latency, and maintain reliable performance. Here are five tools and libraries that are commonly used in the HFT space:\n",
      "\n",
      "1. **FIX Protocol Libraries:**\n",
      "   - The Financial Information eXchange (FIX) protocol is a standard messaging protocol for the real-time exchange of securities transactions. Libraries like QuickFIX (available in C++, Java, Python, and .NET) are frequently used in HFT systems to communicate with trading venues.\n",
      "\n",
      "2. **Quantlib:**\n",
      "   - QuantLib is an open-source library for quantitative finance. It offers tools for modeling, trading strategy development, and risk management, although it is more commonly used for derivatives pricing and risk analytics than for HFT itself.\n",
      "\n",
      "3. **KDB+/q:**\n",
      "   - KDB+ is a high-performance time-series database used extensively in HFT. It is known for its lightning-fast data retrieval and ability to handle large datasets, making it ideal for analyzing market data. The q programming language, used with KDB+, is designed for efficient querying and data analysis.\n",
      "\n",
      "4. **Nanoseconds-Precise Libraries:**\n",
      "   - Libraries designed for low-latency operations are crucial. For example, Aeron offers high-speed messaging, and Chronicle Queue provides low-latency persistent queues commonly used in HFT applications.\n",
      "\n",
      "5. **Apache Kafka:**\n",
      "   - While not solely for HFT, Kafka is a distributed streaming platform that can handle large amounts of real-time data. It is useful for building scalable and resilient data pipelines, often required in HFT for ingesting and processing market data.\n",
      "\n",
      "These tools and libraries collectively provide the infrastructure and capabilities needed to build robust high-frequency trading systems. Note that successful HFT operations also depend heavily on proprietary algorithms and access to low-latency network infrastructure.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e50506-208d-4db9-9f05-220b09946098",
   "metadata": {},
   "source": [
    "## RAG - Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11bc334c-aee1-469b-9b3f-c54cc05aad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5d9f58-fd31-4f82-8e72-5417fb8d291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e277514-745f-4715-a917-3ceaf7bb52e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '628c37060246', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'uhL8fz6vRcmsRJgIZ4b9Lg', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09c2d86-4f7e-4dd9-a828-72cab66af5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.create(index=index_name, body=_index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c1a4f8-688e-4572-b589-eae7a2e3fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./documents.json\") as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19418e89-4631-4973-aad9-d6fa63399635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:01<00:00, 513.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name,document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "549e655d-618c-4c10-b3fa-919d295be3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "class SimpleRAG:\n",
    "\n",
    "    def __init__(self, model) -> None:\n",
    "        self.model = model\n",
    "        self.es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "                    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "                    CONTEXT: \n",
    "                    {context}\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                (\"human\", \"{question}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def elastic_search(self, query: str):\n",
    "        search_query = {\n",
    "            \"size\": 5,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"course\": \"data-engineering-zoomcamp\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        response = es_client.search(index=index_name, body=search_query)\n",
    "        \n",
    "        result_docs = []\n",
    "        \n",
    "        for hit in response['hits']['hits']:\n",
    "            result_docs.append(hit['_source'])\n",
    "        \n",
    "        return result_docs\n",
    "\n",
    "    def query(self, question: str):\n",
    "        search_results = self.elastic_search(question)\n",
    "        chain = self.prompt | self.model\n",
    "        response = chain.invoke(\n",
    "            {\n",
    "                \"context\": search_results, # elasticsearch \n",
    "                \"question\": question,\n",
    "            }\n",
    "        )\n",
    "        # print(search_results)\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed1ae5-64e4-4c2d-a02b-d9b7ef7a6689",
   "metadata": {},
   "source": [
    "## Using the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fd8dd6a-4f17-4057-b313-4225186bdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "es_rag = SimpleRAG(\n",
    "    model=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfc1c5b4-bfcb-42b0-81db-bd01f03e3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_QUERY = 'What do I need to know before taking the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecd26007-2775-4122-8921-94a6ef0ac3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before taking the course, you can start by installing and setting up all the dependencies and requirements, which include a Google Cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. Additionally, it would be beneficial to look over the prerequisites and syllabus to ensure you are comfortable with the subjects covered in the course.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_rag.query(question=BASE_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd235f-a252-489b-80ac-436f4658e106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
